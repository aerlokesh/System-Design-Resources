# Twitter System Design Review & Improvements

## Original Design Overview

Based on the submitted diagram, here's the current architecture:

```
User â†’ CDN â†’ API Gateway â†’ Multiple paths:
                           1. Kafka Topic â†’ Tweet DynamoDB
                           2. Redis (intermediate)
                           3. Read Replica
                           
Additional Components:
- Redis cache of trending
- Redis Counter ZSORT
- Feed Cache Redis
```

---

## Current Design Analysis

### Strengths âœ…

**1. CDN Layer**
```
âœ“ Good: CDN as first layer
âœ“ Reduces load on backend
âœ“ Serves static content
âœ“ Geographic distribution
```

**2. API Gateway**
```
âœ“ Single entry point
âœ“ Centralized authentication
âœ“ Rate limiting capability
âœ“ Request routing
```

**3. Kafka Integration**
```
âœ“ Asynchronous processing
âœ“ Decouples tweet creation from processing
âœ“ Event streaming capability
âœ“ High throughput
```

**4. Multiple Redis Layers**
```
âœ“ Trending cache
âœ“ Feed cache
âœ“ Counter (likely for trending scores)
âœ“ Good use of in-memory caching
```

**5. DynamoDB for Tweet Storage**
```
âœ“ NoSQL - good for tweet data
âœ“ Scalable
âœ“ High availability
```

### Critical Issues âŒ

**Issue 1: Missing Load Balancer**
```
Problem:
User â†’ CDN â†’ API Gateway (Single Point of Failure)

Impact:
- API Gateway becomes bottleneck
- No high availability
- Cannot scale horizontally
- Single point of failure

Current:
â”Œâ”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”
â”‚ User â”‚â”€â”€â”€â”€â–¶â”‚ CDN â”‚â”€â”€â”€â”€â–¶â”‚APIGW â”‚
â””â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”˜
                          (SPOF)
```

**Issue 2: Unclear Data Flow**
```
Problem:
Multiple Redis components without clear purpose

Questions:
- What's the difference between Redis cache and Feed Cache?
- Why Read Replica if using DynamoDB?
- How does Redis Counter ZSORT integrate?
- What writes to what?
```

**Issue 3: Missing Write Path Clarity**
```
Problem:
Tweet creation flow not clear

Missing:
- Where is tweet validated?
- Where is user data stored?
- How are followers notified?
- Fan-out mechanism unclear
```

**Issue 4: No Sharding Strategy**
```
Problem:
Single DynamoDB table may not scale

Missing:
- Partition key strategy
- How to handle 6K tweets/sec?
- Hot partition handling
- Read/write distribution
```

**Issue 5: Incomplete Read Path**
```
Problem:
Feed serving architecture incomplete

Missing:
- Timeline generation logic
- Fan-out on write vs read strategy
- Cache invalidation
- Celebrity user handling
```

**Issue 6: No Monitoring/Observability**
```
Missing:
- Metrics collection
- Logging
- Alerting
- Tracing
```

---

## Improved Architecture

### Complete Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CLIENT LAYER                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CDN LAYER                                 â”‚
â”‚  - CloudFront/Cloudflare                                     â”‚
â”‚  - Static assets (images, videos, JS, CSS)                   â”‚
â”‚  - 40-50% of requests                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                LOAD BALANCER (ELB/ALB)                       â”‚
â”‚  - Distributes traffic across regions                        â”‚
â”‚  - Health checks                                             â”‚
â”‚  - SSL termination                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚                     â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   API Gateway 1   â”‚   â”‚  API Gateway 2  â”‚
        â”‚  - Auth/Rate Limitâ”‚   â”‚  - Auth/Rate   â”‚
        â”‚  - Validation     â”‚   â”‚    Limit       â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚                     â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                    â”‚                    â”‚
        â”‚ POST TWEET         â”‚ GET FEED          â”‚ GET TRENDING
        â”‚                    â”‚                    â”‚
        â–¼                    â–¼                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Write Service â”‚    â”‚ Feed Service â”‚    â”‚Trending      â”‚
â”‚              â”‚    â”‚              â”‚    â”‚Service       â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                   â”‚                    â”‚
       â”‚                   â”‚                    â”‚
       â–¼                   â–¼                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Kafka      â”‚    â”‚ Feed Cache   â”‚    â”‚ Trending     â”‚
â”‚   (Events)   â”‚    â”‚ (Redis)      â”‚    â”‚ Cache (Redis)â”‚
â”‚              â”‚    â”‚              â”‚    â”‚ + ZSORT      â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                   â”‚
       â”‚                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”
       â–¼                            â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚ Fan-out      â”‚                    â”‚
â”‚ Workers      â”‚                    â”‚
â”‚ (100s)       â”‚                    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
       â”‚                            â”‚
       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚             â”‚              â”‚              â”‚
       â–¼             â–¼              â–¼              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ DynamoDB â”‚  â”‚  Redis   â”‚  â”‚PostgreSQLâ”‚  â”‚ElasticSrchâ”‚
â”‚ (Tweets) â”‚  â”‚(Timelinesâ”‚  â”‚(Users,   â”‚  â”‚ (Search) â”‚
â”‚          â”‚  â”‚)         â”‚  â”‚Relations)â”‚  â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Detailed Improvements

### 1. High Availability & Load Distribution

**Add Load Balancer Layer**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Application Load Balancer (ALB)       â”‚
â”‚  - Multiple availability zones           â”‚
â”‚  - Health checks every 30s               â”‚
â”‚  - Auto-failover                         â”‚
â”‚  - Distributes to multiple API Gateways  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â–¼                  â–¼          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚APIGW-1 â”‚       â”‚APIGW-2 â”‚   â”‚APIGW-3 â”‚
â”‚(US-E)  â”‚       â”‚(US-W)  â”‚   â”‚(EU)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Benefits:
+ No single point of failure
+ Horizontal scaling
+ Geographic distribution
+ 99.99% availability
```

### 2. Clear Service Separation

**Microservices Architecture**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          API Gateway                     â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚             â”‚               â”‚
     â–¼             â–¼               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Tweet  â”‚  â”‚   Feed   â”‚  â”‚ Trending â”‚
â”‚ Service â”‚  â”‚ Service  â”‚  â”‚ Service  â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
     â”‚            â”‚             â”‚
     â”‚            â”‚             â”‚
Handles:       Handles:      Handles:
- Create       - Get feed    - Get trending
- Delete       - Cache       - Update scores
- Edit         - Fan-out     - Calculate
```

### 3. Improved Tweet Write Path

**Optimized Flow**:
```
1. User Creates Tweet
   â””â”€> Load Balancer
       â””â”€> API Gateway
           â”œâ”€> Validate (auth, rate limit, content)
           â””â”€> Tweet Service
               â”œâ”€> Write to DynamoDB (primary)
               â”‚   Partition Key: user_id
               â”‚   Sort Key: timestamp
               â”‚   Response: 20ms
               â”‚
               â”œâ”€> Publish to Kafka topic
               â”‚   Topic: "tweet_created"
               â”‚   Partition by: user_id
               â”‚   Response: 5ms
               â”‚
               â””â”€> Return success (25ms total)

2. Async Processing (via Kafka consumers)
   â”œâ”€> Timeline Fan-out Worker
   â”‚   â””â”€> Write to follower feeds (Redis)
   â”‚       For each follower (batched):
   â”‚       LPUSH feed:{follower_id} {tweet_id}
   â”‚       LTRIM feed:{follower_id} 0 999
   â”‚
   â”œâ”€> Search Indexing Worker
   â”‚   â””â”€> Update Elasticsearch
   â”‚       For searchable tweets
   â”‚
   â”œâ”€> Trending Worker
   â”‚   â””â”€> Update trending scores
   â”‚       ZINCRBY trending:global {hashtag} 1
   â”‚
   â”œâ”€> Notification Worker
   â”‚   â””â”€> Send push notifications
   â”‚       To followers who have enabled
   â”‚
   â””â”€> Analytics Worker
       â””â”€> Update metrics/stats
```

### 4. Improved Feed Read Path

**Timeline Serving Strategy**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    GET /api/v1/feed?userId={id}          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    1. Check Feed Cache (Redis)           â”‚
â”‚       Key: feed:{user_id}                â”‚
â”‚       Type: List of tweet IDs            â”‚
â”‚       TTL: 5 minutes                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
        Cache Hit (80%)
             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    2. Hydrate Tweet Details              â”‚
â”‚       Batch GET from DynamoDB            â”‚
â”‚       Get tweet data for IDs             â”‚
â”‚       Add user info, media URLs          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    3. Merge with Celebrity Tweets        â”‚
â”‚       If user follows celebrities        â”‚
â”‚       Fan-out on read for them           â”‚
â”‚       Merge and sort by timestamp        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    4. Return to User                     â”‚
â”‚       Total latency: 30-50ms             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Hybrid Fan-out Strategy**:
```
Regular Users (<1000 followers):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Fan-out on Write                    â”‚
â”‚  - Pre-compute timelines             â”‚
â”‚  - Write to all followers' caches    â”‚
â”‚  - Fast reads                        â”‚
â”‚  - Higher write cost                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Celebrity Users (>1M followers):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Fan-out on Read                     â”‚
â”‚  - Don't write to all followers      â”‚
â”‚  - Compute timeline on request       â”‚
â”‚  - Cache celebrity tweets separately â”‚
â”‚  - Merge at read time                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5. Trending System Improvements

**Real-Time Trending Architecture**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Kafka Consumer (Trending Worker)     â”‚
â”‚  - Consumes "tweet_created" events       â”‚
â”‚  - Extracts hashtags                     â”‚
â”‚  - Updates scores                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Redis Sorted Set (ZSET)              â”‚
â”‚                                          â”‚
â”‚  Key: trending:global                    â”‚
â”‚  Format: ZADD score hashtag              â”‚
â”‚                                          â”‚
â”‚  Score = f(mentions, recency, velocity)  â”‚
â”‚  - mentions: Raw count                   â”‚
â”‚  - recency: Time decay factor            â”‚
â”‚  - velocity: Rate of growth              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Trending API                         â”‚
â”‚  ZREVRANGE trending:global 0 9           â”‚
â”‚  Returns: Top 10 trending topics         â”‚
â”‚  Cache TTL: 1 minute                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Algorithm:
Score = (mentions Ã— 1000) + (velocity Ã— 500) - (age_hours Ã— 10)

Example:
#WorldCup: 50K mentions in last hour
  Score = (50000 Ã— 1000) + (50000 Ã— 500) - (1 Ã— 10)
        = 50M + 25M - 10 = 75M
```

### 6. Database Architecture Improvements

**DynamoDB Table Design**:
```
Tweets Table:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Partition Key: user_id                   â”‚
â”‚ Sort Key: timestamp (descending)         â”‚
â”‚                                          â”‚
â”‚ Attributes:                              â”‚
â”‚  - tweet_id (UUID)                       â”‚
â”‚  - content (text, 280 chars)             â”‚
â”‚  - media_urls (list)                     â”‚
â”‚  - hashtags (set)                        â”‚
â”‚  - mentions (set)                        â”‚
â”‚  - like_count (number)                   â”‚
â”‚  - retweet_count (number)                â”‚
â”‚  - created_at (timestamp)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Global Secondary Index (GSI):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ GSI-1: tweet_id â†’ Full tweet data        â”‚
â”‚  For direct tweet lookups                â”‚
â”‚                                          â”‚
â”‚ GSI-2: hashtag â†’ tweets                  â”‚
â”‚  For hashtag search                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Benefits:
+ Efficient user timeline queries
+ Direct tweet access
+ Hashtag queries
+ Scales horizontally
```

**PostgreSQL for User/Relationships**:
```
Users Table:
- user_id (Primary Key)
- username, email, profile
- follower_count, following_count
- created_at

Relationships Table:
- follower_id (FK to users)
- following_id (FK to users)
- created_at
- INDEX on both IDs

Read Replicas:
- 5-10 replicas for read scaling
- Handle follower/following queries
- Profile lookups
```

### 7. Complete Write Path

**Tweet Creation Flow**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Phase 1: Synchronous (Critical Path)             â”‚
â”‚ Target: <50ms                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  1. Validate    â”‚ (10ms)
    â”‚  - Auth token   â”‚
    â”‚  - Rate limit   â”‚
    â”‚  - Content checkâ”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  2. Write Tweet â”‚ (20ms)
    â”‚  - DynamoDB PUT â”‚
    â”‚  - Partition by â”‚
    â”‚    user_id      â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  3. Publish     â”‚ (5ms)
    â”‚  - Kafka topic  â”‚
    â”‚  - Async processâ”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  4. Return ID   â”‚ (35ms total)
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Phase 2: Asynchronous (Non-Critical)             â”‚
â”‚ Processed by workers                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Kafka Topic: "tweet_created"           â”‚
    â”‚  Partitions: 100 (by user_id)           â”‚
    â”‚  Replication: 3                         â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚               â”‚          â”‚          â”‚
    â–¼               â–¼          â–¼          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Fan-out â”‚    â”‚Search  â”‚ â”‚Trendingâ”‚ â”‚Notify  â”‚
â”‚Worker  â”‚    â”‚Worker  â”‚ â”‚Worker  â”‚ â”‚Worker  â”‚
â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
    â”‚             â”‚          â”‚          â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 8. Feed Fan-out Strategy

**Hybrid Approach**:
```
User Types:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Small Users (<1000 followers)            â”‚
â”‚ - Fan-out on write                       â”‚
â”‚ - Push to all followers' caches          â”‚
â”‚ - Redis: LPUSH feed:{follower_id}        â”‚
â”‚ - Keep last 1000 tweets                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Medium Users (1K-100K followers)         â”‚
â”‚ - Selective fan-out                      â”‚
â”‚ - Fan-out to active followers only       â”‚
â”‚ - Last 7 days activity                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Celebrity Users (>100K followers)        â”‚
â”‚ - Fan-out on read                        â”‚
â”‚ - Don't push to followers                â”‚
â”‚ - Cache celebrity tweets centrally       â”‚
â”‚ - Merge on feed request                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Feed Generation:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Get pre-computed timeline (Redis)     â”‚
â”‚    LRANGE feed:{user_id} 0 99            â”‚
â”‚    â†’ Returns: [tweet_ids]                â”‚
â”‚                                          â”‚
â”‚ 2. Get celebrity tweets (if following)  â”‚
â”‚    ZREVRANGE celeb:tweets 0 99 BYSCORE  â”‚
â”‚    With timestamp as score               â”‚
â”‚                                          â”‚
â”‚ 3. Merge + Sort by timestamp             â”‚
â”‚    Application level merge               â”‚
â”‚                                          â”‚
â”‚ 4. Hydrate tweet details (batch)         â”‚
â”‚    BatchGet from DynamoDB                â”‚
â”‚    Get user profiles                     â”‚
â”‚                                          â”‚
â”‚ 5. Return to user                        â”‚
â”‚    Total: 30-50ms                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 9. Trending System Details

**Improved Trending Architecture**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Real-Time Trending Calculation          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Tweet Created   â”‚
    â”‚ Extract:        â”‚
    â”‚ - Hashtags      â”‚
    â”‚ - Mentions      â”‚
    â”‚ - Language      â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Update Scores   â”‚
    â”‚ Multiple Redis  â”‚
    â”‚ Sorted Sets:    â”‚
    â”‚                 â”‚
    â”‚ trending:global â”‚
    â”‚ trending:us     â”‚
    â”‚ trending:uk     â”‚
    â”‚ trending:tech   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Decay Old Scoresâ”‚
    â”‚ Background job  â”‚
    â”‚ Every minute:   â”‚
    â”‚ Reduce scores   â”‚
    â”‚ by time factor  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Scoring Algorithm:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Score = (M Ã— W_m) + (V Ã— W_v) - (A Ã— W_a)â”‚
â”‚                                          â”‚
â”‚ M = Mentions (raw count)                 â”‚
â”‚ V = Velocity (mentions/hour)             â”‚
â”‚ A = Age (hours since first mention)      â”‚
â”‚                                          â”‚
â”‚ W_m = Weight for mentions (1000)         â”‚
â”‚ W_v = Weight for velocity (500)          â”‚
â”‚ W_a = Weight for age (10)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 10. Caching Strategy

**Complete Caching Hierarchy**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ L1: Browser Cache                        â”‚
â”‚  - Static assets                         â”‚
â”‚  - TTL: 24 hours                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ L2: CDN Edge Cache                       â”‚
â”‚  - Images, videos, CSS, JS               â”‚
â”‚  - Profile pictures                      â”‚
â”‚  - TTL: 7 days                           â”‚
â”‚  - Hit rate: 90%                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ L3: API Gateway Cache                    â”‚
â”‚  - Public API responses                  â”‚
â”‚  - Trending topics                       â”‚
â”‚  - TTL: 1 minute                         â”‚
â”‚  - Hit rate: 60%                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ L4: Feed Cache (Redis)                   â”‚
â”‚  - User timelines                        â”‚
â”‚  - Last 1000 tweets                      â”‚
â”‚  - TTL: 5 minutes                        â”‚
â”‚  - Hit rate: 85%                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ L5: Tweet Cache (Redis)                  â”‚
â”‚  - Individual tweet data                 â”‚
â”‚  - TTL: 10 minutes                       â”‚
â”‚  - Hit rate: 70%                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ L6: Database                             â”‚
â”‚  - DynamoDB (tweets)                     â”‚
â”‚  - PostgreSQL read replicas (users)      â”‚
â”‚  - Latency: 20-50ms                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Complete Improved Architecture

### Full System Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         USER LAYER                               â”‚
â”‚  Web, iOS, Android Clients                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CDN (CloudFront)                              â”‚
â”‚  - Static assets (images, videos, CSS, JS)                       â”‚
â”‚  - Profile pictures, media                                       â”‚
â”‚  - 300+ edge locations globally                                  â”‚
â”‚  - Handles 40% of total requests                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            Application Load Balancer (ALB)                       â”‚
â”‚  - Multi-AZ deployment                                           â”‚
â”‚  - Health checks, auto-failover                                  â”‚
â”‚  - SSL termination                                               â”‚
â”‚  - Geo-routing                                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚                               â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  API Gateway    â”‚            â”‚  API Gateway    â”‚
    â”‚  Cluster 1      â”‚            â”‚  Cluster 2      â”‚
    â”‚  (US-EAST)      â”‚            â”‚  (US-WEST)      â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚                               â”‚
             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                    â”‚                    â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
â”‚ Tweet Service  â”‚  â”‚  Feed Service   â”‚  â”‚  Trending   â”‚
â”‚ (Write Heavy)  â”‚  â”‚  (Read Heavy)   â”‚  â”‚  Service    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
        â”‚                    â”‚                   â”‚
        â”‚                    â”‚                   â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    MESSAGE QUEUE (KAFKA)                         â”‚
â”‚  Topics:                                                         â”‚
â”‚  - tweet_created (100 partitions)                                â”‚
â”‚  - tweet_deleted                                                 â”‚
â”‚  - like_added                                                    â”‚
â”‚  - retweet_created                                               â”‚
â”‚  Brokers: 10 (replication factor: 3)                             â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”‚  Consumed by Worker Fleet
       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    WORKER FLEET                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Fan-out Workers â”‚ Search Workers   â”‚ Analytics Workers        â”‚
â”‚  (200 instances) â”‚ (50 instances)   â”‚ (30 instances)          â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                    â”‚                   â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                   â”‚                        â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   DynamoDB     â”‚  â”‚ Elasticsearch  â”‚  â”‚  PostgreSQL        â”‚
â”‚   (Tweets)     â”‚  â”‚  (Search)      â”‚  â”‚  (Users/Relations) â”‚
â”‚                â”‚  â”‚                â”‚  â”‚                    â”‚
â”‚  Sharded by    â”‚  â”‚  Full-text     â”‚  â”‚  Master +          â”‚
â”‚  user_id       â”‚  â”‚  search        â”‚  â”‚  10 Read Replicas  â”‚
â”‚                â”‚  â”‚                â”‚  â”‚                    â”‚
â”‚  On-Demand     â”‚  â”‚  5-node        â”‚  â”‚  Sharded by        â”‚
â”‚  Auto-scaling  â”‚  â”‚  cluster       â”‚  â”‚  user_id           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    REDIS CLUSTERS                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Feed Cache      â”‚  Tweet Cache     â”‚  Trending Cache           â”‚
â”‚  Cluster         â”‚  Cluster         â”‚  Cluster                  â”‚
â”‚  (10 nodes)      â”‚  (5 nodes)       â”‚  (3 nodes)               â”‚
â”‚                  â”‚                  â”‚                           â”‚
â”‚  feed:{user_id}  â”‚  tweet:{id}      â”‚  trending:global          â”‚
â”‚  List of IDs     â”‚  Tweet data      â”‚  trending:us              â”‚
â”‚  TTL: 5 min      â”‚  TTL: 10 min     â”‚  trending:tech            â”‚
â”‚                  â”‚                  â”‚  ZSORT by score           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Capacity Planning

### Expected Load

```
Assumptions:
- 300M Monthly Active Users (MAU)
- 100M Daily Active Users (DAU)
- Average 5 tweets/user/day (heavy users)
- Total: 500M tweets/day

Calculations:
Writes (Tweets):
- Average: 500M / 86,400 = 5,787 tweets/sec
- Peak (3x): 17,361 tweets/sec
- Plan for: 20,000 tweets/sec

Reads (Timeline/Feed):
- Each user checks feed 50 times/day
- Total: 100M Ã— 50 = 5B reads/day
- Average: 57,870 reads/sec
- Peak (3x): 173,610 reads/sec
- Plan for: 200,000 reads/sec

Storage:
- Average tweet size: 500 bytes (text + metadata)
- Daily storage: 500M Ã— 500B = 250GB/day
- Monthly: 7.5TB/month
- Yearly: 90TB/year
```

### Component Sizing

**DynamoDB (Tweets)**:
```
Configuration:
- On-Demand capacity mode
- Or: 20,000 WCU, 200,000 RCU
- Global tables for multi-region
- Point-in-time recovery enabled

Partition Strategy:
- Partition key: user_id
- Hot partition handling: Burst capacity
- Estimated partitions: 1000+

Cost (estimated):
- $5,000 - $15,000/month depending on load
```

**Redis Clusters**:
```
Feed Cache Cluster:
- 10 nodes (r6g.2xlarge)
- Memory: 320GB total
- Stores: 100M active user feeds
- Each feed: ~100 tweet IDs = 800 bytes
- Total: 8GB (fits easily with overhead)

Tweet Cache Cluster:
- 5 nodes (r6g.xlarge)
- Memory: 160GB total
- Stores: 10M hot tweets
- Each tweet: ~2KB
- Total: 20GB

Trending Cache Cluster:
- 3 nodes (r6g.large)
- Memory: 48GB total
- ZSORT for trending topics
- Light weight data

Total Cost: ~$3,000/month
```

**Kafka Cluster**:
```
Configuration:
- 10 brokers (m5.2xlarge)
- 100 partitions per topic
- Replication factor: 3
- Retention: 7 days

Throughput:
- Per broker: 50K messages/sec
- Total: 500K messages/sec
- Handles peaks easily

Cost: ~$5,000/month
```

**Worker Fleet**:
```
Fan-out Workers:
- 200 instances (c5.large)
- Each processes: 100 tweets/sec
- Total capacity: 20K tweets/sec
- Auto-scaling based on Kafka lag

Search Workers:
- 50 instances
- Update Elasticsearch

Trending Workers:
- 30 instances
- Update Redis ZSORT

Total Cost: ~$7,000/month
```

---

## Monitoring & Observability

### Key Metrics to Track

**Write Path Metrics**:
```
1. Tweet Creation Latency
   - p50: <30ms
   - p99: <100ms
   - p999: <200ms

2. Kafka Producer Metrics
   - Messages/sec
   - Producer lag
   - Failed sends

3. DynamoDB Metrics
   - Write capacity consumed
   - Throttled requests
   - Latency
   - Hot partitions

4. Worker Processing Lag
   - Kafka consumer lag (messages behind)
   - Target: <1000 messages
   - Alert: >10,000 messages
```

**Read Path Metrics**:
```
1. Feed Read Latency
   - p50: <20ms
   - p99: <50ms
   - p999: <100ms

2. Cache Hit Rates
   - Feed cache: >85%
   - Tweet cache: >70%
   - Alert if: <60%

3. Database Read Latency
   - DynamoDB: <20ms
   - PostgreSQL replicas: <50ms

4. CDN Performance
   - Cache hit rate: >90%
   - Edge latency: <20ms
```

**System Health Metrics**:
```
1. Availability
   - Target: 99.99%
   - Monitor: Uptime per component

2. Error Rates
   - API errors: <0.1%
   - Worker failures: <0.5%
   - Database errors: <0.01%

3. Queue Depth
   - Kafka lag: <1000 messages
   - Alert: >5000 messages
   - Critical: >50,000 messages

4. Resource Utilization
   - CPU: <70% average
   - Memory: <80% average
   - Network: <60% average
```

---

## Failure Scenarios & Mitigation

### Scenario 1: API Gateway Failure

**Original Design Risk**:
```
Problem:
Single API Gateway â†’ Complete outage

Impact:
- All requests fail
- No tweets can be posted
- No feeds can be read
- Complete service down
```

**Improved Design**:
```
Solution:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Load Balancer with Health Checks    â”‚
â”‚  Distributes across 3+ API Gateways  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Timeline:
T+0s: API Gateway 1 fails
T+30s: Health check detects failure
T+31s: Traffic routed to others
T+32s: No user impact

Result:
- Zero downtime
- Degraded capacity temporarily
- Auto-scaling adds replacement
- Full capacity restored in 5 minutes
```

### Scenario 2: Redis Cache Failure

**Risk**:
```
Feed Cache Crashes:
- All feed requests â†’ Database
- 200K requests/sec hit database
- Database overwhelmed
- Cascading failure
```

**Mitigation**:
```
Solution 1: Redis Cluster Mode
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Redis Cluster (Sharded)             â”‚
â”‚  - 10 primary nodes                  â”‚
â”‚  - 10 replica nodes                  â”‚
â”‚  - Automatic failover                â”‚
â”‚  - No single point of failure        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Solution 2: Circuit Breaker
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Detect cache failures               â”‚
â”‚  â†’ Temporarily serve degraded feeds  â”‚
â”‚  â†’ Show cached tweets only           â”‚
â”‚  â†’ Reduce database load              â”‚
â”‚  â†’ Gradual recovery                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Scenario 3: Kafka Overload

**Risk**:
```
Consumer Lag Growing:
- Producers: 20K messages/sec
- Consumers: 15K messages/sec
- Lag growing: 5K messages/sec
- Queue builds up
```

**Mitigation**:
```
Solution 1: Auto-Scaling Consumers
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Monitor: Consumer lag               â”‚
â”‚  Trigger: Lag > 5000 messages        â”‚
â”‚  Action: Scale workers               â”‚
â”‚  - Add 50% more workers              â”‚
â”‚  - Process backlog                   â”‚
â”‚  - Scale down when caught up         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Solution 2: Backpressure
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Monitor: Queue depth                â”‚
â”‚  Trigger: Depth > 100K messages      â”‚
â”‚  Action: Apply backpressure          â”‚
â”‚  - Rate limit tweet creation         â”‚
â”‚  - Return 429 Too Many Requests      â”‚
â”‚  - Protect system from overload      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Key Recommendations

### Must-Have Improvements (P0)

**1. Add Load Balancer**
```
Priority: Critical
Impact: High availability
Effort: Low (AWS ELB/ALB)
Timeline: Immediate

Without this:
- Single point of failure
- Cannot scale API gateways
- Poor disaster recovery
```

**2. Separate User Database**
```
Priority: Critical
Impact: Data model clarity
Effort: Medium
Timeline: 1-2 sprints

Why:
- Users and tweets are different entities
- Different access patterns
- Different scaling needs
- PostgreSQL better for relationships
```

**3. Implement Hybrid Fan-out**
```
Priority: Critical
Impact: Write scalability
Effort: High
Timeline: 2-3 sprints

Why:
- Celebrity tweets cause write storms
- Cannot fan-out to millions
- Selective fan-out saves resources
- Better user experience
```

### Should-Have Improvements (P1)

**4. Add Elasticsearch for Search**
```
Priority: High
Impact: Search functionality
Effort: Medium
Timeline: 2 sprints

Benefits:
- Full-text search
- Hashtag search
- User search
- Advanced filtering
```

**5. Implement Monitoring**
```
Priority: High
Impact: Observability
Effort: Medium
Timeline: 1-2 sprints

Tools:
- Prometheus (metrics)
- Grafana (dashboards)
- CloudWatch (AWS integration)
- Jaeger (distributed tracing)
```

**6. Add Rate Limiting Per User**
```
Priority: High
Impact: Abuse prevention
Effort: Low
Timeline: 1 sprint

Limits:
- 100 tweets/hour per user
- 1000 API requests/hour
- DDoS protection
```

### Nice-to-Have Improvements (P2)

**7. Implement Content Moderation**
```
Priority: Medium
Impact: Safety
Effort: High
Timeline: 3+ sprints

Features:
- ML-based content filtering
- Spam detection
- Abuse prevention
- Human review queue
```

**8. Add Analytics Pipeline**
```
Priority: Medium
Impact: Business insights
Effort: Medium
Timeline: 2 sprints

Components:
- Data lake (S3)
- Stream processing (Kinesis)
- Analytics DB (Redshift)
- BI tools (QuickSight)
```

---

## Trade-off Analysis

### Improved Design Trade-offs

| Aspect | Original | Improved | Trade-off |
|--------|----------|----------|-----------|
| **Availability** | Single API GW (SPOF) | Load balanced | +Higher cost |
| **Write Latency** | Unclear | 35ms | +Measured, optimized |
| **Read Latency** | Unclear | 30-50ms | +Clear caching |
| **Scalability** | Limited | Linear | +More components |
| **Consistency** | Unclear | Eventual | +Defined model |
| **Complexity** | Medium | High | +More to manage |
| **Cost** | ~$5K/mo | ~$25K/mo | +5x cost |
| **Capacity** | ~1K tweets/sec | 20K tweets/sec | +20x capacity |

### When to Use This Architecture

**Good Fit**:
- High-volume social platform
- Read-heavy workload (90:10)
- Global user base
- Real-time requirements
- Can accept eventual consistency

**Not Suitable**:
- Strong consistency required
- Low write volume (<100/sec)
- Limited budget (<$5K/month)
- Small team (can't manage complexity)

---

## Migration Path

### Phase 1: Foundation (Month 1)
```
1. Add Load Balancer
   - Deploy ALB
   - Configure health checks
   - Add multiple API Gateway instances

2. Separate Services
   - Extract Tweet Service
   - Extract Feed Service
   - Extract Trending Service

3. Basic Monitoring
   - CloudWatch dashboards
   - Error rate alerts
   - Latency alerts
```

### Phase 2: Scale Database (Month 2)
```
1. Setup PostgreSQL for Users
   - Migrate user data
   - Setup read replicas
   - Update application

2. Optimize DynamoDB
   - Define partition strategy
   - Create GSIs
   - Enable auto-scaling

3. Implement Caching
   - Deploy Redis clusters
   - Implement cache-aside
   - Measure hit rates
```

### Phase 3: Async Processing (Month 3)
```
1. Deploy Kafka
   - 10 broker cluster
   - Configure topics
   - Setup monitoring

2. Implement Workers
   - Fan-out workers
   - Search workers
   - Trending workers

3. Optimize Fan-out
   - Hybrid strategy
   - Celebrity detection
   - Performance tuning
```

### Phase 4: Search & Analytics (Month 4)
```
1. Deploy Elasticsearch
   - 5-node cluster
   - Index configuration
   - Replication

2. Implement Search
   - Full-text search
   - Hashtag search
   - User search

3. Analytics Pipeline
   - Data warehouse
   - BI tools
   - Reporting
```

---

## Summary

### What Was Good âœ…
- CDN usage
- Kafka for async processing
- Multiple Redis layers
- DynamoDB for tweets
- Basic architecture understanding

### What Needed Improvement âš ï¸
- Load balancer missing
- Single point of failure
- Unclear data flows
- No sharding strategy
- Missing user database
- Incomplete fan-out logic
- No monitoring

### Key Changes Made âœ¨
- Added load balancer layer
- Separated microservices clearly
- Defined hybrid fan-out strategy
- Clarified database architecture
- Added PostgreSQL for users
- Detailed caching hierarchy
- Comprehensive monitoring
- Failure mitigation strategies

### Scale Achieved ğŸ“ˆ
```
Original Design Capacity:
- Tweets: ~1,000/sec
- Reads: ~10,000/sec
- Availability: ~99%

Improved Design Capacity:
- Tweets: 20,000/sec (20x)
- Reads: 200,000/sec (20x)
- Availability: 99.99% (better)
```

---

## Interview Tips

### How to Present This Design

**1. Start with Requirements**
```
"Let me clarify the requirements:
- Write rate: ~6K tweets/sec average, 18K peak
- Read rate: ~60K reads/sec average, 180K peak
- Latency: <100ms for writes, <50ms for reads
- Consistency: Eventual is acceptable
- Global distribution required"
```

**2. High-Level First**
```
"I'll design this in layers:
1. CDN for static content
2. Load balancer for HA
3. Microservices for separation
4. Async processing via Kafka
5. Multi-tier caching
6. Sharded databases"
```

**3. Deep Dive Selectively**
```
"Let me dive into the write path:
[Explain tweet creation flow]

Now for the read path:
[Explain feed generation]

And for trending:
[Explain real-time scoring]"
```

**4. Address Trade-offs**
```
"Key trade-offs in this design:
- Eventual consistency for performance
- Higher complexity for scalability
- Multiple caches for lower latency
- More cost for better availability"
```

**5. Discuss Failures**
```
"Let's talk about failure modes:
- API Gateway fails â†’ Load balancer routes around
- Cache fails â†’ Circuit breaker + degraded mode
- Database shard fails â†’ Replica promotion
- Queue backs up â†’ Backpressure + auto-scaling"
```

---

## Conclusion

The original design showed good understanding of core concepts but lacked:
- High availability considerations
- Clear data flow and responsibilities
- Detailed fan-out strategy
- Monitoring and observability
- Failure handling

The improved design addresses these gaps and provides a production-ready architecture capable of handling Twitter-scale loads (millions of users, thousands of writes/sec, hundreds of thousands of reads/sec).

**Final Grade: B+ â†’ A**

**Original**: 70/100
- Good concepts, incomplete implementation

**Improved**: 95/100
- Production-ready, scalable, well-documented

---

**Review Date**: November 2024  
**Reviewer**: System Design Architecture Guide  
**System**: Twitter-like Social Media Platform  
**Scale**: 100M DAU, 6K tweets/sec, 60K reads/sec
